{
  "workflowName": "atac",
  "actualWorkflowLanguageVersion": "draft-2",
  "submittedFiles": {
    "workflow": "# ENCODE DCC ATAC-Seq/DNase-Seq pipeline\n# Author: Jin Lee (leepc12@gmail.com)\n\nworkflow atac {\n\tString pipeline_ver = 'v1.1.6'\n\t### sample name, description\n\tString title = 'Untitled'\n\tString description = 'No description'\n\n\t### pipeline type\n\tString pipeline_type = 'atac'\t# ATAC-Seq (atac) or DNase-Seq (dnase)\n\t\t\t\t\t\t\t\t\t# the only difference is that tn5 shiting is enabled for atac\n\t### mandatory genome param\n\tFile genome_tsv \t\t# reference genome data TSV file including\n\t\t\t\t\t\t\t# all important genome specific data file paths and parameters\n\tBoolean paired_end\n\n\t### optional but important\n\tBoolean align_only = false\t\t# disable all post-align analysis (peak-calling, overlap, idr, ...)\n\tBoolean true_rep_only = false \t# disable all analyses for pseudo replicates\n\t\t\t\t\t\t\t\t\t# overlap and idr will also be disabled\n\n\tBoolean auto_detect_adapter = false\t# automatically detect/trim adapters\n\tInt cutadapt_min_trim_len = 5\t# minimum trim length for cutadapt -m\n\tFloat cutadapt_err_rate = 0.1\t# Maximum allowed adapter error rate for cutadapt -e\t\n\n\tInt multimapping = 0\t\t\t# for multimapping reads\n\n\tString bowtie2_score_min = ''\t# min acceptable alignment score func w.r.t read length\n\n\tString dup_marker = 'picard'\t# picard MarkDuplicates (picard) or sambamba markdup (sambamba)\n\tInt mapq_thresh = 30\t\t\t# threshold for low MAPQ reads removal\n\tBoolean no_dup_removal = false \t# no dupe reads removal when filtering BAM\n\t\t\t\t\t\t\t\t\t# dup.qc and pbc.qc will be empty files\n\t\t\t\t\t\t\t\t\t# and nodup_bam in the output is filtered bam with dupes\n\n\tString mito_chr_name = 'chrM' \t# name of mito chromosome. THIS IS NOT A REG-EX! you can define only one chromosome name for mito.\n\tString regex_filter_reads = 'chrM' \t# Perl-style regular expression pattern for chr name to filter out reads\n\t\t\t\t\t\t\t\t\t# those reads with this chromosome name (in the 1st column) will be excluded from peak calling\n\tInt subsample_reads = 0\t\t# number of reads to subsample TAGALIGN\n\t\t\t\t\t\t\t\t# 0 for no subsampling. this affects all downstream analysis\n\n\tBoolean enable_xcor = false \t# enable cross-correlation analysis\n\tInt xcor_subsample_reads = 25000000\t# number of reads to subsample TAGALIGN\n\t\t\t\t\t\t\t\t# this will be used for xcor only\n\t\t\t\t\t\t\t\t# will not affect any downstream analysis\n\n\tBoolean keep_irregular_chr_in_bfilt_peak = false # when filtering with blacklist\n\t\t\t\t\t\t\t\t# do not filter peaks with irregular chr name\n\t\t\t\t\t\t\t\t# and just keep them in bfilt_peak file\n\t\t\t\t\t\t\t\t# (e.g. keep chr1_AABBCC, AABR07024382.1, ...)\n\t\t\t\t\t\t\t\t# reg-ex pattern for regular chr names: /chr[\\dXY]+[ \\t]/\n\tInt cap_num_peak = 300000\t# cap number of raw peaks called from MACS2\n\tFloat pval_thresh = 0.01\t# p.value threshold for MACS2\n\tInt smooth_win = 150\t\t# size of smoothing window\n\n\tBoolean enable_idr = false \t# enable IDR analysis on raw peaks\n\tFloat idr_thresh = 0.1\t\t# IDR threshold\n\n\tBoolean disable_ataqc = false\n\n\t### resources (disks: for cloud platforms)\n\tInt trim_adapter_cpu = 2\n\tInt trim_adapter_mem_mb = 12000\n\tInt trim_adapter_time_hr = 24\n\tString trim_adapter_disks = \"local-disk 100 HDD\"\n\n\tInt bowtie2_cpu = 4\n\tInt bowtie2_mem_mb = 20000\n\tInt bowtie2_time_hr = 48\n\tString bowtie2_disks = \"local-disk 100 HDD\"\n\n\tInt filter_cpu = 2\n\tInt filter_mem_mb = 20000\n\tInt filter_time_hr = 24\n\tString filter_disks = \"local-disk 100 HDD\"\n\n\tInt bam2ta_cpu = 2\n\tInt bam2ta_mem_mb = 10000\n\tInt bam2ta_time_hr = 6\n\tString bam2ta_disks = \"local-disk 100 HDD\"\n\n\tInt spr_mem_mb = 16000\n\n\tInt xcor_cpu = 2\n\tInt xcor_mem_mb = 16000\n\tInt xcor_time_hr = 6\n\tString xcor_disks = \"local-disk 100 HDD\"\n\n\tInt macs2_mem_mb = 16000\n\tInt macs2_time_hr = 24\n\tString macs2_disks = \"local-disk 100 HDD\"\n\n\tInt ataqc_mem_mb = 16000\n\tInt ataqc_mem_java_mb = 15000\n\tInt ataqc_time_hr = 24\n\tString ataqc_disks = \"local-disk 400 HDD\"\n\n\t#### input file definition\n\t\t# pipeline can start from any type of inputs and then leave all other types undefined\n\t\t# supported types: fastq, bam, nodup_bam (filtered bam), ta (tagAlign), peak\n\t\t# define up to 6 replicates\n\t\t# [rep_id] is for each replicate\n\n \t### fastqs and adapters  \t\n\t \t# define fastqs either with DNANexus style (1-dim array) or with default one (3-dim array)\n\t \t# [merge_id] is for pooing fastqs after trimming adapters\n\t \t# if adapters defined with any style, keep the same structure/dimension as fastq arrays\n\t \t# only defined adapters will be trimmed\n\t \t# or undefined adapters will be detected/trimmed by trim_adapter.auto_detect_adapter=true \n\t \t# so you can selectively detect/trim adapters for a specific fastq\n \t## DNANexus UI style fastq/adapter definition\n\tArray[File] fastqs_rep1_R1 = []\t# [merge_id]\n\tArray[File] fastqs_rep1_R2 = [] # do not define _R2 array if your sample is not paired end\n\tArray[File] fastqs_rep2_R1 = [] # do not define if you have a single replicate\n\tArray[File] fastqs_rep2_R2 = []\t# do not define _R2 array if your sample is not paired end\n\tArray[File] fastqs_rep3_R1 = [] # do not define if you have <=2 replicates\n\tArray[File] fastqs_rep3_R2 = []\t# do not define _R2 array if your sample is not paired end\n\tArray[File] fastqs_rep4_R1 = [] # do not define if you have <=3 replicates\n\tArray[File] fastqs_rep4_R2 = []\t# do not define _R2 array if your sample is not paired end\n\tArray[File] fastqs_rep5_R1 = [] # do not define if you have <=4 replicates\n\tArray[File] fastqs_rep5_R2 = []\t# do not define _R2 array if your sample is not paired end\n\tArray[File] fastqs_rep6_R1 = [] # do not define if you have <=5 replicates\n\tArray[File] fastqs_rep6_R2 = []\t# do not define _R2 array if your sample is not paired end\n\tArray[String] adapters_rep1_R1 = [] # [merge_id]\n\tArray[String] adapters_rep1_R2 = [] \n\tArray[String] adapters_rep2_R1 = []\n\tArray[String] adapters_rep2_R2 = []\n\tArray[String] adapters_rep3_R1 = []\n\tArray[String] adapters_rep3_R2 = []\n\tArray[String] adapters_rep4_R1 = []\n\tArray[String] adapters_rep4_R2 = []\n\tArray[String] adapters_rep5_R1 = []\n\tArray[String] adapters_rep5_R2 = []\n\tArray[String] adapters_rep6_R1 = []\n\tArray[String] adapters_rep6_R2 = []\n \t## default style fastq/adapter definition\n \t\t# [read_end_id] is for fastq R1 or fastq R2\n\tArray[Array[Array[File]]] fastqs = [] \t# [rep_id][merge_id][read_end_id]\n\tArray[Array[Array[File]]] adapters = []\t# [rep_id][merge_id][read_end_id]\n\n\t### other input types (bam, nodup_bam, ta)\n\tArray[File] bams = [] \t\t# [rep_id]\n\tArray[File] nodup_bams = [] # [rep_id]\n\tArray[File] tas = []\t\t# [rep_id]\n\n\t### other input types (peak)\n\tArray[File] peaks = []\t\t# [PAIR(rep_id1,rep_id2)]. example for 3 reps: [rep1_rep2, rep1_rep3, rep2_rep3]\n\tArray[File] peaks_pr1 = []\t# [rep_id]. do not define if true_rep=true\n\tArray[File] peaks_pr2 = []\t# [rep_id]. do not define if true_rep=true\n\tFile? peak_ppr1\t\t\t\t# do not define if you have a single replicate or true_rep=true\n\tFile? peak_ppr2\t\t\t\t# do not define if you have a single replicate or true_rep=true\n\tFile? peak_pooled\t\t\t# do not define if you have a single replicate or true_rep=true\n\n\t### other inputs used for resuming pipelines (QC/txt/log/png files, ...)\n\tFile? ta_pooled\n\tArray[File] read_len_logs = []\n\tArray[File] flagstat_qcs = []\n\tArray[File] align_logs = []\n\tArray[File] pbc_qcs = []\n\tArray[File] dup_qcs = []\n\tArray[File] nodup_flagstat_qcs = []\n\tArray[File] mito_dup_logs = []\n\tArray[File] sig_pvals = []\n\tArray[File] xcor_plots = []\n\tArray[File] xcor_scores = []\n\tArray[File] macs2_frip_qcs = []\n\tArray[File] macs2_pr1_frip_qcs = []\n\tArray[File] macs2_pr2_frip_qcs = []\n\tFile? macs2_pooled_frip_qc_\n\tFile? macs2_ppr1_frip_qc_\n\tFile? macs2_ppr2_frip_qc_\n\tArray[File] ataqc_htmls = []\n\tArray[File] ataqc_txts = []\n\n\t### read genome data and paths\n\tcall read_genome_tsv { input:genome_tsv = genome_tsv }\n\tFile bowtie2_idx_tar = read_genome_tsv.genome['bowtie2_idx_tar']\n\tFile blacklist = read_genome_tsv.genome['blacklist']\n\tFile chrsz = read_genome_tsv.genome['chrsz']\n\tString gensz = read_genome_tsv.genome['gensz']\n\tFile ref_fa = read_genome_tsv.genome['ref_fa']\n\t# genome data for ATAQC\n\tFile tss_enrich = read_genome_tsv.genome['tss_enrich']\n\tFile dnase = read_genome_tsv.genome['dnase']\n\tFile prom = read_genome_tsv.genome['prom']\n\tFile enh = read_genome_tsv.genome['enh']\n\tFile reg2map = read_genome_tsv.genome['reg2map']\n\tFile reg2map_bed = read_genome_tsv.genome['reg2map_bed']\n\tFile roadmap_meta = read_genome_tsv.genome['roadmap_meta']\n\n\t### temp vars (do not define these)\n\tString peak_type = 'narrowPeak' # peak type for IDR and overlap\n\tString idr_rank = 'p.value' # IDR ranking method\n\n\t### pipeline starts here\n\t# temporary 2-dim arrays for DNANexus style fastqs and adapters\t\n\tArray[Array[File]] fastqs_rep1 = if length(fastqs_rep1_R2)>0 then transpose([fastqs_rep1_R1,fastqs_rep1_R2])\n\t\t\t\t\t\t\t\t\telse transpose([fastqs_rep1_R1])\n\tArray[Array[File]] fastqs_rep2 = if length(fastqs_rep2_R2)>0 then transpose([fastqs_rep2_R1,fastqs_rep2_R2])\n\t\t\t\t\t\t\t\t\telse transpose([fastqs_rep2_R1])\n\tArray[Array[File]] fastqs_rep3 = if length(fastqs_rep3_R2)>0 then transpose([fastqs_rep3_R1,fastqs_rep3_R2])\n\t\t\t\t\t\t\t\t\telse transpose([fastqs_rep3_R1])\n\tArray[Array[File]] fastqs_rep4 = if length(fastqs_rep4_R2)>0 then transpose([fastqs_rep4_R1,fastqs_rep4_R2])\n\t\t\t\t\t\t\t\t\telse transpose([fastqs_rep4_R1])\n\tArray[Array[File]] fastqs_rep5 = if length(fastqs_rep5_R2)>0 then transpose([fastqs_rep5_R1,fastqs_rep5_R2])\n\t\t\t\t\t\t\t\t\telse transpose([fastqs_rep5_R1])\n\tArray[Array[File]] fastqs_rep6 = if length(fastqs_rep6_R2)>0 then transpose([fastqs_rep6_R1,fastqs_rep6_R2])\n\t\t\t\t\t\t\t\t\telse transpose([fastqs_rep6_R1])\n\tArray[Array[String]] adapters_rep1 = if length(adapters_rep1_R2)>0 then transpose([adapters_rep1_R1,adapters_rep1_R2])\n\t\t\t\t\t\t\t\t\telse transpose([adapters_rep1_R1])\n\tArray[Array[String]] adapters_rep2 = if length(adapters_rep2_R2)>0 then transpose([adapters_rep2_R1,adapters_rep2_R2])\n\t\t\t\t\t\t\t\t\telse transpose([adapters_rep2_R1])\n\tArray[Array[String]] adapters_rep3 = if length(adapters_rep3_R2)>0 then transpose([adapters_rep3_R1,adapters_rep3_R2])\n\t\t\t\t\t\t\t\t\telse transpose([adapters_rep3_R1])\n\tArray[Array[String]] adapters_rep4 = if length(adapters_rep4_R2)>0 then transpose([adapters_rep4_R1,adapters_rep4_R2])\n\t\t\t\t\t\t\t\t\telse transpose([adapters_rep4_R1])\n\tArray[Array[String]] adapters_rep5 = if length(adapters_rep5_R2)>0 then transpose([adapters_rep5_R1,adapters_rep5_R2])\n\t\t\t\t\t\t\t\t\telse transpose([adapters_rep5_R1])\n\tArray[Array[String]] adapters_rep6 = if length(adapters_rep6_R2)>0 then transpose([adapters_rep6_R1,adapters_rep6_R2])\n\t\t\t\t\t\t\t\t\telse transpose([adapters_rep6_R1])\n\n\tArray[Array[Array[File]]] fastqs_ = if length(fastqs_rep1)<1 then fastqs\n\t\telse if length(fastqs_rep2)<1 then [fastqs_rep1]\n\t\telse if length(fastqs_rep3)<1 then [fastqs_rep1,fastqs_rep2]\n\t\telse if length(fastqs_rep4)<1 then [fastqs_rep1,fastqs_rep2,fastqs_rep3]\n\t\telse if length(fastqs_rep5)<1 then [fastqs_rep1,fastqs_rep2,fastqs_rep3,fastqs_rep4]\n\t\telse if length(fastqs_rep6)<1 then [fastqs_rep1,fastqs_rep2,fastqs_rep3,fastqs_rep4,fastqs_rep5]\n\t\telse [fastqs_rep1,fastqs_rep2,fastqs_rep3,fastqs_rep4,fastqs_rep5,fastqs_rep6]\n\tArray[Array[Array[String]]] adapters_ = if length(adapters_rep1)<1 then adapters\n\t\telse if length(adapters_rep2)<1 then [adapters_rep1]\n\t\telse if length(adapters_rep3)<1 then [adapters_rep1,adapters_rep2]\n\t\telse if length(adapters_rep4)<1 then [adapters_rep1,adapters_rep2,adapters_rep3]\n\t\telse if length(adapters_rep5)<1 then [adapters_rep1,adapters_rep2,adapters_rep3,adapters_rep4]\n\t\telse if length(adapters_rep6)<1 then [adapters_rep1,adapters_rep2,adapters_rep3,adapters_rep4,adapters_rep5]\n\t\telse [adapters_rep1,adapters_rep2,adapters_rep3,adapters_rep4,adapters_rep5,adapters_rep6]\n\n\t## temp vars for resuming pipelines\n\tBoolean need_to_process_ta = length(peaks_pr1)==0 && length(peaks)==0\n\tBoolean need_to_process_nodup_bam = need_to_process_ta && length(tas)==0\n\tBoolean need_to_process_bam = need_to_process_nodup_bam && length(nodup_bams)==0\n\tBoolean need_to_process_fastq = need_to_process_bam && length(bams)==0\n\n\tscatter( i in range(if need_to_process_fastq then length(fastqs_) else 0) ) {\n\t\t# trim adapters and merge trimmed fastqs\n\t\tcall trim_adapter { input :\n\t\t\tfastqs = fastqs_[i],\n\t\t\tadapters = if length(adapters_)>0 then adapters_[i] else [],\n\t\t\tauto_detect_adapter = auto_detect_adapter,\n\t\t\tpaired_end = paired_end,\n\t\t\tmin_trim_len = cutadapt_min_trim_len,\n\t\t\terr_rate = cutadapt_err_rate,\n\n\t\t\tcpu = trim_adapter_cpu,\n\t\t\tmem_mb = trim_adapter_mem_mb,\n\t\t\ttime_hr = trim_adapter_time_hr,\n\t\t\tdisks = trim_adapter_disks,\n\t\t}\n\t\t# align trimmed/merged fastqs with bowtie2s\n\t\tcall bowtie2 { input :\n\t\t\tidx_tar = bowtie2_idx_tar,\n\t\t\tfastqs = trim_adapter.trimmed_merged_fastqs, #[R1,R2]\n\t\t\tscore_min = bowtie2_score_min,\n\t\t\tpaired_end = paired_end,\n\t\t\tmultimapping = multimapping,\n\n\t\t\tcpu = bowtie2_cpu,\n\t\t\tmem_mb = bowtie2_mem_mb,\n\t\t\ttime_hr = bowtie2_time_hr,\n\t\t\tdisks = bowtie2_disks,\n\t\t}\n\t}\n\n\tArray[File] bams_ = flatten([bowtie2.bam, bams])\n\tscatter( bam in if need_to_process_bam then bams_ else [] ) {\n\t\t# filter/dedup bam\n\t\tcall filter { input :\n\t\t\tbam = bam,\n\t\t\tpaired_end = paired_end,\n\t\t\tdup_marker = dup_marker,\n\t\t\tmapq_thresh = mapq_thresh,\n\t\t\tno_dup_removal = no_dup_removal,\n\t\t\tmultimapping = multimapping,\n\t\t\tmito_chr_name = mito_chr_name,\n\n\t\t\tcpu = filter_cpu,\n\t\t\tmem_mb = filter_mem_mb,\n\t\t\ttime_hr = filter_time_hr,\n\t\t\tdisks = filter_disks,\n\t\t}\n\t}\n\n\tArray[File] nodup_bams_ = flatten([filter.nodup_bam, nodup_bams])\n\tscatter( bam in if need_to_process_nodup_bam then nodup_bams_ else [] ) {\n\t\t# convert bam to tagalign and subsample it if necessary\n\t\tcall bam2ta { input :\n\t\t\tbam = bam,\n\t\t\tdisable_tn5_shift = if pipeline_type=='atac' then false else true,\n\t\t\tregex_grep_v_ta = regex_filter_reads,\n\t\t\tsubsample = subsample_reads,\n\t\t\tpaired_end = paired_end,\n\t\t\tmito_chr_name = mito_chr_name,\n\n\t\t\tcpu = bam2ta_cpu,\n\t\t\tmem_mb = bam2ta_mem_mb,\n\t\t\ttime_hr = bam2ta_time_hr,\n\t\t\tdisks = bam2ta_disks,\t\t\t\n\t\t}\n\t}\n\n\tArray[File] tas_ = if align_only then [] else flatten([bam2ta.ta, tas])\n\tArray[File] tas__ = if need_to_process_ta then tas_ else []\n\tscatter( ta in tas__ ) {\n\t\t# call peaks on tagalign\n\t\tcall macs2 { input :\n\t\t\tta = ta,\n\t\t\tgensz = gensz,\n\t\t\tchrsz = chrsz,\n\t\t\tcap_num_peak = cap_num_peak,\n\t\t\tpval_thresh = pval_thresh,\n\t\t\tsmooth_win = smooth_win,\n\t\t\tmake_signal = true,\n\t\t\tblacklist = blacklist,\n\t\t\tkeep_irregular_chr_in_bfilt_peak = keep_irregular_chr_in_bfilt_peak,\n\n\t\t\tmem_mb = macs2_mem_mb,\n\t\t\tdisks = macs2_disks,\n\t\t\ttime_hr = macs2_time_hr,\n\t\t}\n\t}\n\tif ( length(tas__)>1 ) {\n\t\t# pool tagaligns from true replicates\n\t\tcall pool_ta { input :\n\t\t\ttas = tas__,\n\t\t}\n\t\t# call peaks on pooled replicate\n\t\tcall macs2 as macs2_pooled { input :\n\t\t\tta = pool_ta.ta_pooled,\n\t\t\tgensz = gensz,\n\t\t\tchrsz = chrsz,\n\t\t\tcap_num_peak = cap_num_peak,\n\t\t\tpval_thresh = pval_thresh,\n\t\t\tsmooth_win = smooth_win,\n\t\t\tmake_signal = true,\n\t\t\tblacklist = blacklist,\n\t\t\tkeep_irregular_chr_in_bfilt_peak = keep_irregular_chr_in_bfilt_peak,\n\n\t\t\tmem_mb = macs2_mem_mb,\n\t\t\tdisks = macs2_disks,\n\t\t\ttime_hr = macs2_time_hr,\n\t\t}\n\t}\n\tif ( enable_xcor && length(xcor_scores)<1 ) {\n\t\tscatter( ta in tas__ ) {\n\t\t\t# subsample tagalign (non-mito) and cross-correlation analysis\n\t\t\tcall xcor { input :\n\t\t\t\tta = ta,\n\t\t\t\tsubsample = xcor_subsample_reads,\n\t\t\t\tpaired_end = paired_end,\n\t\t\t\tmito_chr_name = mito_chr_name,\n\n\t\t\t\tcpu = xcor_cpu,\n\t\t\t\tmem_mb = xcor_mem_mb,\n\t\t\t\ttime_hr = xcor_time_hr,\n\t\t\t\tdisks = xcor_disks,\t\t\t\t\n\t\t\t}\n\t\t}\n\t}\n\n\tif ( !true_rep_only ) {\n\t\tscatter( ta in tas__ ) {\n\t\t\t# make two self pseudo replicates per true replicate\n\t\t\tcall spr { input :\n\t\t\t\tta = ta,\n\t\t\t\tpaired_end = paired_end,\n\t\t\t\tmem_mb = spr_mem_mb,\n\t\t\t}\n\t\t\t# call peaks on 1st pseudo replicated tagalign \n\t\t\tcall macs2 as macs2_pr1 { input :\n\t\t\t\tta = spr.ta_pr1,\n\t\t\t\tgensz = gensz,\n\t\t\t\tchrsz = chrsz,\n\t\t\t\tcap_num_peak = cap_num_peak,\n\t\t\t\tpval_thresh = pval_thresh,\n\t\t\t\tsmooth_win = smooth_win,\n\t\t\t\tblacklist = blacklist,\n\t\t\t\tmake_signal = false,\n\t\t\t\tkeep_irregular_chr_in_bfilt_peak = keep_irregular_chr_in_bfilt_peak,\n\n\t\t\t\tmem_mb = macs2_mem_mb,\n\t\t\t\tdisks = macs2_disks,\n\t\t\t\ttime_hr = macs2_time_hr,\n\t\t\t}\n\t\t\t# call peaks on 2nd pseudo replicated tagalign \n\t\t\tcall macs2 as macs2_pr2 { input :\n\t\t\t\tta = spr.ta_pr2,\n\t\t\t\tgensz = gensz,\n\t\t\t\tchrsz = chrsz,\n\t\t\t\tcap_num_peak = cap_num_peak,\n\t\t\t\tpval_thresh = pval_thresh,\n\t\t\t\tsmooth_win = smooth_win,\n\t\t\t\tblacklist = blacklist,\n\t\t\t\tmake_signal = false,\n\t\t\t\tkeep_irregular_chr_in_bfilt_peak = keep_irregular_chr_in_bfilt_peak,\n\n\t\t\t\tmem_mb = macs2_mem_mb,\n\t\t\t\tdisks = macs2_disks,\n\t\t\t\ttime_hr = macs2_time_hr,\n\t\t\t}\n\t\t}\n\t}\n\n\tif ( !true_rep_only && length(tas__)>1 ) {\n\t\t# pool tagaligns from pseudo replicates\n\t\tcall pool_ta as pool_ta_pr1 { input :\n\t\t\ttas = spr.ta_pr1,\n\t\t}\n\t\tcall pool_ta as pool_ta_pr2 { input :\n\t\t\ttas = spr.ta_pr2,\n\t\t}\n\t\t# call peaks on 1st pooled pseudo replicates\n\t\tcall macs2 as macs2_ppr1 { input :\n\t\t\tta = pool_ta_pr1.ta_pooled,\n\t\t\tgensz = gensz,\n\t\t\tchrsz = chrsz,\n\t\t\tcap_num_peak = cap_num_peak,\n\t\t\tpval_thresh = pval_thresh,\n\t\t\tsmooth_win = smooth_win,\n\t\t\tblacklist = blacklist,\n\t\t\tmake_signal = false,\n\t\t\tkeep_irregular_chr_in_bfilt_peak = keep_irregular_chr_in_bfilt_peak,\n\n\t\t\tmem_mb = macs2_mem_mb,\n\t\t\tdisks = macs2_disks,\n\t\t\ttime_hr = macs2_time_hr,\n\t\t}\n\t\t# call peaks on 2nd pooled pseudo replicates\n\t\tcall macs2 as macs2_ppr2 { input :\n\t\t\tta = pool_ta_pr2.ta_pooled,\n\t\t\tgensz = gensz,\n\t\t\tchrsz = chrsz,\n\t\t\tcap_num_peak = cap_num_peak,\n\t\t\tpval_thresh = pval_thresh,\n\t\t\tsmooth_win = smooth_win,\n\t\t\tblacklist = blacklist,\n\t\t\tmake_signal = false,\n\t\t\tkeep_irregular_chr_in_bfilt_peak = keep_irregular_chr_in_bfilt_peak,\n\n\t\t\tmem_mb = macs2_mem_mb,\n\t\t\tdisks = macs2_disks,\n\t\t\ttime_hr = macs2_time_hr,\n\t\t}\n\t}\n\n\t# make peak arrays\n\tArray[File] peaks_ = flatten([macs2.npeak, peaks])\n\n\t# generate all possible pairs of true replicates (pair: left=prefix, right=[peak1,peak2])\n\tArray[Pair[String,Array[File]]] peak_pairs =  \n\t\tif length(peaks_)<=1 then [] # 1 rep\n\t\telse if length(peaks_)<=2 then # 2 reps\n\t\t\t [('rep1-rep2',[peaks_[0],peaks_[1]])]\n\t\telse if length(peaks_)<=3 then # 3 reps\n\t\t\t [('rep1-rep2',[peaks_[0],peaks_[1]]), ('rep1-rep3',[peaks_[0],peaks_[2]]),\n\t\t\t  ('rep2-rep3',[peaks_[1],peaks_[2]])]\n\t\telse if length(peaks_)<=4 then # 4 reps\n\t\t\t [('rep1-rep2',[peaks_[0],peaks_[1]]), ('rep1-rep3',[peaks_[0],peaks_[2]]), ('rep1-rep4',[peaks_[0],peaks_[3]]),\n\t\t\t  ('rep2-rep3',[peaks_[1],peaks_[2]]), ('rep2-rep4',[peaks_[1],peaks_[3]]),\n\t\t\t  ('rep3-rep4',[peaks_[2],peaks_[3]])]\n\t\telse if length(peaks_)<=5 then # 5 reps\n\t\t\t [('rep1-rep2',[peaks_[0],peaks_[1]]), ('rep1-rep3',[peaks_[0],peaks_[2]]), ('rep1-rep4',[peaks_[0],peaks_[3]]), ('rep1-rep5',[peaks_[0],peaks_[4]]),\n\t\t\t  ('rep2-rep3',[peaks_[1],peaks_[2]]), ('rep2-rep4',[peaks_[1],peaks_[3]]), ('rep2-rep5',[peaks_[1],peaks_[4]]),\n\t\t\t  ('rep3-rep4',[peaks_[2],peaks_[3]]), ('rep3-rep5',[peaks_[2],peaks_[4]]),\n\t\t\t  ('rep4-rep5',[peaks_[3],peaks_[4]])]\n\t\telse # 6 reps\n\t\t\t [('rep1-rep2',[peaks_[0],peaks_[1]]), ('rep1-rep3',[peaks_[0],peaks_[2]]), ('rep1-rep4',[peaks_[0],peaks_[3]]), ('rep1-rep5',[peaks_[0],peaks_[4]]), ('rep1-rep6',[peaks_[0],peaks_[5]]),\n\t\t\t  ('rep2-rep3',[peaks_[1],peaks_[2]]), ('rep2-rep4',[peaks_[1],peaks_[3]]), ('rep2-rep5',[peaks_[1],peaks_[4]]), ('rep2-rep6',[peaks_[1],peaks_[5]]),\n\t\t\t  ('rep3-rep4',[peaks_[2],peaks_[3]]), ('rep3-rep5',[peaks_[2],peaks_[4]]), ('rep3-rep6',[peaks_[2],peaks_[5]]),\n\t\t\t  ('rep4-rep5',[peaks_[3],peaks_[4]]), ('rep4-rep6',[peaks_[3],peaks_[5]]),\n\t\t\t  ('rep5-rep6',[peaks_[4],peaks_[5]])]\n\tif ( length(peaks_)>0 ) {\n\t\tscatter( pair in peak_pairs ) {\n\t\t\t# Naive overlap on every pair of true replicates\n\t\t\tcall overlap { input :\n\t\t\t\tprefix = pair.left,\n\t\t\t\tpeak1 = pair.right[0],\n\t\t\t\tpeak2 = pair.right[1],\n\t\t\t\tpeak_pooled = select_first([macs2_pooled.npeak, peak_pooled]),\n\t\t\t\tpeak_type = peak_type,\n\t\t\t\tblacklist = blacklist,\n\t\t\t\tchrsz = chrsz,\n\t\t\t\tkeep_irregular_chr_in_bfilt_peak = keep_irregular_chr_in_bfilt_peak,\n\t\t\t\tta = if defined(ta_pooled) then ta_pooled else pool_ta.ta_pooled,\n\t\t\t}\n\t\t}\n\t}\n\tif ( length(peaks_)>0 && enable_idr ) {\n\t\tscatter( pair in peak_pairs ) {\n\t\t\t# IDR on every pair of true replicates\n\t\t\tcall idr { input : \n\t\t\t\tprefix = pair.left,\n\t\t\t\tpeak1 = pair.right[0],\n\t\t\t\tpeak2 = pair.right[1],\n\t\t\t\tpeak_pooled = select_first([macs2_pooled.npeak, peak_pooled]),\n\t\t\t\tidr_thresh = idr_thresh,\n\t\t\t\tpeak_type = peak_type,\n\t\t\t\trank = idr_rank,\n\t\t\t\tblacklist = blacklist,\n\t\t\t\tchrsz = chrsz,\n\t\t\t\tkeep_irregular_chr_in_bfilt_peak = keep_irregular_chr_in_bfilt_peak,\n\t\t\t\tta = if defined(ta_pooled) then ta_pooled else pool_ta.ta_pooled,\n\t\t\t}\n\t\t}\n\t}\n\n\tArray[File] peaks_pr1_ = flatten(select_all([macs2_pr1.npeak, peaks_pr1]))\n\tArray[File] peaks_pr2_ = flatten(select_all([macs2_pr2.npeak, peaks_pr2]))\n\n\tscatter( i in range(length(peaks_pr1_)) ) {\n\t\t# Naive overlap on pseduo replicates\n\t\tcall overlap as overlap_pr { input : \n\t\t\tprefix = \"rep\"+(i+1)+\"-pr\",\n\t\t\tpeak1 = peaks_pr1_[i],\n\t\t\tpeak2 = peaks_pr2_[i],\n\t\t\tpeak_pooled = peaks_[i],\n\t\t\tpeak_type = peak_type,\n\t\t\tblacklist = blacklist,\n\t\t\tchrsz = chrsz,\n\t\t\tkeep_irregular_chr_in_bfilt_peak = keep_irregular_chr_in_bfilt_peak,\n\t\t\tta = if length(tas_)>0 then tas_[i] else if defined(ta_pooled) then ta_pooled else pool_ta.ta_pooled,\n\t\t}\n\t}\n\tif ( enable_idr ) {\n\t\tscatter( i in range(length(peaks_pr1_)) ) {\n\t\t\t# IDR on pseduo replicates\n\t\t\tcall idr as idr_pr { input : \n\t\t\t\tprefix = \"rep\"+(i+1)+\"-pr\",\n\t\t\t\tpeak1 = peaks_pr1_[i],\n\t\t\t\tpeak2 = peaks_pr2_[i],\n\t\t\t\tpeak_pooled = peaks_[i],\n\t\t\t\tidr_thresh = idr_thresh,\n\t\t\t\tpeak_type = peak_type,\n\t\t\t\trank = idr_rank,\n\t\t\t\tblacklist = blacklist,\n\t\t\t\tchrsz = chrsz,\n\t\t\t\tkeep_irregular_chr_in_bfilt_peak = keep_irregular_chr_in_bfilt_peak,\n\t\t\t\tta = if length(tas_)>0 then tas_[i] else if defined(ta_pooled) then ta_pooled else pool_ta.ta_pooled,\n\t\t\t}\n\t\t}\n\t}\n\tif ( length(peaks_pr1_)>1 ) {\n\t\t# Naive overlap on pooled pseudo replicates\n\t\tcall overlap as overlap_ppr { input : \n\t\t\tprefix = \"ppr\",\n\t\t\tpeak1 = select_first([macs2_ppr1.npeak, peak_ppr1]),\n\t\t\tpeak2 = select_first([macs2_ppr2.npeak, peak_ppr2]),\n\t\t\tpeak_pooled = select_first([macs2_pooled.npeak, peak_pooled]),\n\t\t\tpeak_type = peak_type,\n\t\t\tblacklist = blacklist,\n\t\t\tchrsz = chrsz,\n\t\t\tkeep_irregular_chr_in_bfilt_peak = keep_irregular_chr_in_bfilt_peak,\n\t\t\tta = if defined(ta_pooled) then ta_pooled else pool_ta.ta_pooled\n\t\t}\n\t}\n\tif ( enable_idr && length(peaks_pr1_)>1  ) {\n\t\t# IDR on pooled pseduo replicates\n\t\tcall idr as idr_ppr { input : \n\t\t\tprefix = \"ppr\",\n\t\t\tpeak1 = select_first([macs2_ppr1.npeak, peak_ppr1]),\n\t\t\tpeak2 = select_first([macs2_ppr2.npeak, peak_ppr2]),\n\t\t\tpeak_pooled = select_first([macs2_pooled.npeak, peak_pooled]),\n\t\t\tidr_thresh = idr_thresh,\n\t\t\tpeak_type = peak_type,\n\t\t\trank = idr_rank,\n\t\t\tblacklist = blacklist,\n\t\t\tchrsz = chrsz,\n\t\t\tkeep_irregular_chr_in_bfilt_peak = keep_irregular_chr_in_bfilt_peak,\n\t\t\tta = if defined(ta_pooled) then ta_pooled else pool_ta.ta_pooled\n\t\t}\n\t}\n\tif ( !align_only && !true_rep_only ) {\n\t\t# reproducibility QC for overlapping peaks\n\t\tcall reproducibility as reproducibility_overlap { input :\n\t\t\tprefix = 'overlap',\n\t\t\tpeaks = overlap.bfilt_overlap_peak,\n\t\t\tpeaks_pr = overlap_pr.bfilt_overlap_peak,\n\t\t\tpeak_ppr = overlap_ppr.bfilt_overlap_peak,\n\t\t\tpeak_type = peak_type,\n\t\t\tchrsz = chrsz,\n\t\t\tkeep_irregular_chr_in_bfilt_peak = keep_irregular_chr_in_bfilt_peak,\n\t\t}\n\t}\n\tif ( !align_only && !true_rep_only && enable_idr ) {\n\t\t# reproducibility QC for IDR peaks\n\t\tcall reproducibility as reproducibility_idr { input :\n\t\t\tprefix = 'idr',\n\t\t\tpeaks = idr.bfilt_idr_peak,\n\t\t\tpeaks_pr = idr_pr.bfilt_idr_peak,\n\t\t\tpeak_ppr = idr_ppr.bfilt_idr_peak,\n\t\t\tpeak_type = peak_type,\n\t\t\tchrsz = chrsz,\n\t\t\tkeep_irregular_chr_in_bfilt_peak = keep_irregular_chr_in_bfilt_peak,\n\t\t}\n\t}\n\n\t# count number of replicates for ataqc\t\n\tInt num_rep = if disable_ataqc || length(ataqc_htmls)>0 then 0\n\t\telse if length(fastqs_)>0 then length(fastqs_)\n\t\telse if length(bams_)>0 then length(bams_)\n\t\telse if length(tas_)>0 then length(tas_)\n\t\telse if length(peaks_pr1)>0 then length(peaks_pr1)\n\t\telse 0\n\tFile? null\n\n\tArray[File] read_len_logs_ = flatten([read_len_logs, bowtie2.read_len_log])\n\tArray[File] flagstat_qcs_ = flatten([flagstat_qcs, bowtie2.flagstat_qc])\n\tArray[File] align_logs_ = flatten([align_logs, bowtie2.align_log])\n\tArray[File] pbc_qcs_ = flatten([pbc_qcs, filter.pbc_qc])\n\tArray[File] dup_qcs_ = flatten([dup_qcs, filter.dup_qc])\n\tArray[File] nodup_flagstat_qcs_ = flatten([nodup_flagstat_qcs, filter.flagstat_qc])\n\tArray[File] mito_dup_logs_ = flatten([mito_dup_logs, filter.mito_dup_log])\n\tArray[File] xcor_plots_ = flatten(select_all([xcor_plots, xcor.plot_png]))\n\tArray[File] xcor_scores_ = flatten(select_all([xcor_scores, xcor.score]))\n\tArray[File] sig_pvals_ = flatten([sig_pvals, macs2.sig_pval])\n\tArray[File] macs2_frip_qcs_ = flatten([macs2_frip_qcs, macs2.frip_qc])\n\tArray[File] macs2_pr1_frip_qcs_ = flatten(select_all([macs2_pr1_frip_qcs, macs2_pr1.frip_qc]))\n\tArray[File] macs2_pr2_frip_qcs_ = flatten(select_all([macs2_pr2_frip_qcs, macs2_pr2.frip_qc]))\n\n\tscatter( i in range(num_rep) ) {\n\t\tcall ataqc { input : \n\t\t\tpaired_end = paired_end,\n\t\t\tread_len_log = if length(read_len_logs_)>0 then read_len_logs_[i] else null,\n\t\t\tflagstat_log = if length(flagstat_qcs_)>0 then flagstat_qcs_[i] else null,\n\t\t\tbowtie2_log = if length(align_logs_)>0 then align_logs_[i] else null,\n\t\t\tpbc_log = if length(pbc_qcs_)>0 then pbc_qcs_[i] else null,\n\t\t\tdup_log = if length(dup_qcs_)>0 then dup_qcs_[i] else null,\n\t\t\tbam = if length(bams_)>0 then bams_[i] else null,\n\t\t\tnodup_flagstat_log = if length(nodup_flagstat_qcs_)>0 then nodup_flagstat_qcs_[i] else null,\n\t\t\tmito_dup_log = if length(mito_dup_logs_)>0 then mito_dup_logs_[i] else null,\n\t\t\tnodup_bam = if length(nodup_bams_)>0 then nodup_bams_[i] else null,\n\t\t\tta = if length(tas_)>0 then tas_[i] else null,\n\t\t\tpeak = if align_only then null\n\t\t\t\t\telse if enable_idr then select_first([idr_pr.bfilt_idr_peak])[i]\n\t\t\t\t\telse reproducibility_overlap.optimal_peak,\n\t\t\tidr_peak = if align_only || !enable_idr then null\n\t\t\t\t\telse reproducibility_idr.optimal_peak, #idr_peaks_ataqc[i],\n\t\t\toverlap_peak= if align_only then null\n\t\t\t\t\telse reproducibility_overlap.optimal_peak, #overlap_peaks_ataqc[i],\n\t\t\tbigwig = if length(sig_pvals_)>0 then sig_pvals_[i] else null,\n\t\t\tref_fa = ref_fa,\n\t\t\tchrsz = chrsz,\n\t\t\ttss_enrich = tss_enrich,\n\t\t\tblacklist = blacklist,\n\t\t\tdnase = dnase,\n\t\t\tprom = prom,\n\t\t\tenh = enh,\n\t\t\treg2map_bed = reg2map_bed,\n\t\t\treg2map = reg2map,\n\t\t\troadmap_meta = roadmap_meta,\n\t\t\tmito_chr_name = mito_chr_name,\n\n\t\t\tmem_mb = ataqc_mem_mb,\n\t\t\tmem_java_mb = ataqc_mem_java_mb,\n\t\t\ttime_hr = ataqc_time_hr,\n\t\t\tdisks = ataqc_disks,\n\t\t}\n\t}\n\n\t# Generate final QC report and JSON\t\t\n\tcall qc_report { input :\n\t\tpipeline_ver = pipeline_ver,\n\t\ttitle = title,\n\t\tdescription = description,\n\t\tgenome = basename(genome_tsv),\n\t\tmultimapping = multimapping,\n\t\tpaired_end = paired_end,\n\t\tpipeline_type = pipeline_type,\n\t\tpeak_caller = 'macs2',\n\t\tmacs2_cap_num_peak = cap_num_peak,\n\t\tidr_thresh = idr_thresh,\n\t\tflagstat_qcs = flagstat_qcs_,\n\t\tnodup_flagstat_qcs = nodup_flagstat_qcs_,\n\t\tdup_qcs = dup_qcs_,\n\t\tpbc_qcs = pbc_qcs_,\n\t\txcor_plots = xcor_plots_,\n\t\txcor_scores = xcor_scores_,\n\n\t\tfrip_macs2_qcs = macs2_frip_qcs_,\n\t\tfrip_macs2_qcs_pr1 = macs2_pr1_frip_qcs_,\n\t\tfrip_macs2_qcs_pr2 = macs2_pr2_frip_qcs_,\n\t\tfrip_macs2_qc_pooled = if defined(macs2_pooled_frip_qc_) then macs2_pooled_frip_qc_ else macs2_pooled.frip_qc,\n\t\tfrip_macs2_qc_ppr1 = if defined(macs2_ppr1_frip_qc_) then macs2_ppr1_frip_qc_ else macs2_ppr1.frip_qc,\n\t\tfrip_macs2_qc_ppr2 = if defined(macs2_ppr2_frip_qc_) then macs2_ppr2_frip_qc_ else macs2_ppr2.frip_qc,\n\n\t\tidr_plots = idr.idr_plot,\n\t\tidr_plots_pr = idr_pr.idr_plot,\n\t\tidr_plot_ppr = idr_ppr.idr_plot,\n\t\tfrip_idr_qcs = idr.frip_qc,\n\t\tfrip_idr_qcs_pr = idr_pr.frip_qc,\n\t\tfrip_idr_qc_ppr = idr_ppr.frip_qc,\n\t\tfrip_overlap_qcs = overlap.frip_qc,\n\t\tfrip_overlap_qcs_pr = overlap_pr.frip_qc,\n\t\tfrip_overlap_qc_ppr = overlap_ppr.frip_qc,\n\t\tidr_reproducibility_qc = reproducibility_idr.reproducibility_qc,\n\t\toverlap_reproducibility_qc = reproducibility_overlap.reproducibility_qc,\n\t\tataqc_txts = flatten([ataqc.txt, ataqc_txts]),\n\t\tataqc_htmls = flatten([ataqc.html, ataqc_htmls]),\n\t}\n\n\toutput {\n\t\tFile report = qc_report.report\n\t\tFile qc_json = qc_report.qc_json\n\t\tBoolean qc_json_ref_match = qc_report.qc_json_ref_match\n\t}\n}\n\ntask trim_adapter { # trim adapters and merge trimmed fastqs\n\tArray[Array[File]] fastqs \t\t# [merge_id][read_end_id]\n\tArray[Array[String]] adapters \t# [merge_id][read_end_id]\n\tBoolean paired_end\n\t# mandatory\n\tBoolean auto_detect_adapter\t# automatically detect/trim adapters\n\t# optional\n\tInt min_trim_len \t\t# minimum trim length for cutadapt -m\n\tFloat err_rate\t\t\t# Maximum allowed adapter error rate \n\t\t\t\t\t\t\t# for cutadapt -e\t\n\tInt cpu\n\tInt mem_mb\n\tInt time_hr\n\tString disks\n\n\tcommand {\n\t\tpython $(which encode_trim_adapter.py) \\\n\t\t\t${write_tsv(fastqs)} \\\n\t\t\t--adapters ${write_tsv(adapters)} \\\n\t\t\t${if paired_end then \"--paired-end\" else \"\"} \\\n\t\t\t${if auto_detect_adapter then \"--auto-detect-adapter\" else \"\"} \\\n\t\t\t${\"--min-trim-len \" + min_trim_len} \\\n\t\t\t${\"--err-rate \" + err_rate} \\\n\t\t\t${\"--nth \" + cpu}\n\t}\n\toutput {\n\t\t# WDL glob() globs in an alphabetical order\n\t\t# so R1 and R2 can be switched, which results in an\n\t\t# unexpected behavior of a workflow\n\t\t# so we prepend merge_fastqs_'end'_ (R1 or R2)\n\t\t# to the basename of original filename\n\t\t# this prefix will be later stripped in bowtie2 task\n\t\tArray[File] trimmed_merged_fastqs = glob(\"merge_fastqs_R?_*.fastq.gz\")\n\t}\n\truntime {\n\t\tcpu : cpu\n\t\tmemory : \"${mem_mb} MB\"\n\t\ttime : time_hr\n\t\tdisks : disks\n\t}\n}\n\ntask bowtie2 {\n\tFile idx_tar \t\t# reference bowtie2 index tar\n\tArray[File] fastqs \t# [read_end_id]\n\tBoolean paired_end\n\tInt multimapping\n\tString score_min \t# min acceptable alignment score func\n\t\t\t\t\t\t# w.r.t read length\n\tInt cpu\n\tInt mem_mb\n\tInt time_hr\n\tString disks\n\n\tcommand {\n\t\tpython $(which encode_bowtie2.py) \\\n\t\t\t${idx_tar} \\\n\t\t\t${sep=' ' fastqs} \\\n\t\t\t${if paired_end then \"--paired-end\" else \"\"} \\\n\t\t\t${\"--multimapping \" + multimapping} \\\n\t\t\t${if score_min!=\"\" then \"--score-min \" + score_min else \"\"} \\\n\t\t\t${\"--nth \" + cpu}\n\t}\n\toutput {\n\t\tFile bam = glob(\"*.bam\")[0]\n\t\tFile bai = glob(\"*.bai\")[0]\n\t\tFile align_log = glob(\"*.align.log\")[0]\n\t\tFile flagstat_qc = glob(\"*.flagstat.qc\")[0]\n\t\tFile read_len_log = glob(\"*.read_length.txt\")[0] # read_len\n\t}\n\truntime {\n\t\tcpu : cpu\n\t\tmemory : \"${mem_mb} MB\"\n\t\ttime : time_hr\n\t\tdisks : disks\n\t\tpreemptible: 0\n\t}\n}\n\ntask filter {\n\tFile bam\n\tBoolean paired_end\n\tInt multimapping\n\tString dup_marker \t\t\t# picard.jar MarkDuplicates (picard) or \n\t\t\t\t\t\t\t\t# sambamba markdup (sambamba)\n\tInt mapq_thresh\t\t\t\t# threshold for low MAPQ reads removal\n\tBoolean no_dup_removal \t\t# no dupe reads removal when filtering BAM\n\t\t\t\t\t\t\t\t# dup.qc and pbc.qc will be empty files\n\t\t\t\t\t\t\t\t# and nodup_bam in the output is \n\t\t\t\t\t\t\t\t# filtered bam with dupes\t\n\tString mito_chr_name\n\tInt cpu\n\tInt mem_mb\n\tInt time_hr\n\tString disks\n\n\tcommand {\n\t\t${if no_dup_removal then \"touch null.dup.qc null.pbc.qc null.mito_dup.txt; \" else \"\"}\n\t\ttouch null\n\t\tpython $(which encode_filter.py) \\\n\t\t\t${bam} \\\n\t\t\t${if paired_end then \"--paired-end\" else \"\"} \\\n\t\t\t${\"--multimapping \" + multimapping} \\\n\t\t\t${\"--dup-marker \" + dup_marker} \\\n\t\t\t${\"--mapq-thresh \" + mapq_thresh} \\\n\t\t\t${if no_dup_removal then \"--no-dup-removal\" else \"\"} \\\n\t\t\t${\"--mito-chr-name \" + mito_chr_name} \\\n\t\t\t${\"--nth \" + cpu}\n\t}\n\toutput {\n\t\tFile nodup_bam = glob(\"*.bam\")[0]\n\t\tFile nodup_bai = glob(\"*.bai\")[0]\n\t\tFile flagstat_qc = glob(\"*.flagstat.qc\")[0]\n\t\tFile dup_qc = if no_dup_removal then glob(\"null\")[0] else glob(\"*.dup.qc\")[0]\n\t\tFile pbc_qc = if no_dup_removal then glob(\"null\")[0] else glob(\"*.pbc.qc\")[0]\n\t\tFile mito_dup_log = if no_dup_removal then glob(\"null\")[0] else glob(\"*.mito_dup.txt\")[0] # mito_dups, fract_dups_from_mito\n\t}\n\truntime {\n\t\tcpu : cpu\n\t\tmemory : \"${mem_mb} MB\"\n\t\ttime : time_hr\n\t\tdisks : disks\n\t}\n}\n\ntask bam2ta {\n\tFile bam\n\tBoolean paired_end\n\tBoolean disable_tn5_shift \t# no tn5 shifting (it's for dnase-seq)\n\tString regex_grep_v_ta   \t# Perl-style regular expression pattern \n                        \t\t# to remove matching reads from TAGALIGN\n\tString mito_chr_name \t\t# mito chromosome name\n\tInt subsample \t\t\t\t# number of reads to subsample TAGALIGN\n\t\t\t\t\t\t\t\t# this affects all downstream analysis\n\tInt cpu\n\tInt mem_mb\n\tInt time_hr\n\tString disks\n\n\tcommand {\n\t\tpython $(which encode_bam2ta.py) \\\n\t\t\t${bam} \\\n\t\t\t${if paired_end then \"--paired-end\" else \"\"} \\\n\t\t\t${if disable_tn5_shift then \"--disable-tn5-shift\" else \"\"} \\\n\t\t\t${if regex_grep_v_ta!=\"\" then \"--regex-grep-v-ta '\"+regex_grep_v_ta+\"'\" else \"\"} \\\n\t\t\t${\"--mito-chr-name \" + mito_chr_name} \\\n\t\t\t${\"--subsample \" + subsample} \\\n\t\t\t${\"--nth \" + cpu}\n\t}\n\toutput {\n\t\tFile ta = glob(\"*.tagAlign.gz\")[0]\n\t}\n\truntime {\n\t\tcpu : cpu\n\t\tmemory : \"${mem_mb} MB\"\n\t\ttime : time_hr\n\t\tdisks : disks\n\t}\n}\n\ntask spr { # make two self pseudo replicates\n\tFile ta\n\tBoolean paired_end\n\n\tInt mem_mb\n\n\tcommand {\n\t\tpython $(which encode_spr.py) \\\n\t\t\t${ta} \\\n\t\t\t${if paired_end then \"--paired-end\" else \"\"}\n\t}\n\toutput {\n\t\tFile ta_pr1 = glob(\"*.pr1.tagAlign.gz\")[0]\n\t\tFile ta_pr2 = glob(\"*.pr2.tagAlign.gz\")[0]\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : \"${mem_mb} MB\"\n\t\ttime : 1\n\t\tdisks : \"local-disk 50 HDD\"\n\t}\n}\n\ntask pool_ta {\n\tArray[File] tas\n\n\tcommand {\n\t\tpython $(which encode_pool_ta.py) \\\n\t\t\t${sep=' ' tas}\n\t}\n\toutput {\n\t\tFile ta_pooled = glob(\"*.tagAlign.gz\")[0]\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : \"4000 MB\"\n\t\ttime : 1\n\t\tdisks : \"local-disk 50 HDD\"\n\t}\n}\n\ntask xcor {\n\tFile ta\n\tBoolean paired_end\n\tString mito_chr_name\n\tInt subsample  # number of reads to subsample TAGALIGN\n\t\t\t\t# this will be used for xcor only\n\t\t\t\t# will not affect any downstream analysis\n\tInt cpu\n\tInt mem_mb\t\n\tInt time_hr\n\tString disks\n\n\tcommand {\n\t\tpython $(which encode_xcor.py) \\\n\t\t\t${ta} \\\n\t\t\t${if paired_end then \"--paired-end\" else \"\"} \\\n\t\t\t${\"--mito-chr-name \" + mito_chr_name} \\\n\t\t\t${\"--subsample \" + subsample} \\\n\t\t\t--speak=0 \\\n\t\t\t${\"--nth \" + cpu}\n\t}\n\toutput {\n\t\tFile plot_pdf = glob(\"*.cc.plot.pdf\")[0]\n\t\tFile plot_png = glob(\"*.cc.plot.png\")[0]\n\t\tFile score = glob(\"*.cc.qc\")[0]\n\t\tInt fraglen = read_int(glob(\"*.cc.fraglen.txt\")[0])\n\t}\n\truntime {\n\t\tcpu : cpu\n\t\tmemory : \"${mem_mb} MB\"\n\t\ttime : time_hr\n\t\tdisks : disks\n\t}\n}\n\ntask macs2 {\n\tFile ta\n\tString gensz\t\t# Genome size (sum of entries in 2nd column of \n                        # chr. sizes file, or hs for human, ms for mouse)\n\tFile chrsz\t\t\t# 2-col chromosome sizes file\n\tInt cap_num_peak\t# cap number of raw peaks called from MACS2\n\tFloat pval_thresh  \t# p.value threshold\n\tInt smooth_win \t\t# size of smoothing window\n\tBoolean make_signal\n\tFile blacklist \t\t# blacklist BED to filter raw peaks\n\tBoolean\tkeep_irregular_chr_in_bfilt_peak\n\t\n\tInt mem_mb\n\tInt time_hr\n\tString disks\n\n\tcommand {\n\t\t${if make_signal then \"\" \n\t\t\telse \"touch null.pval.signal.bigwig null.fc.signal.bigwig\"}\n\t\ttouch null \n\t\tpython $(which encode_macs2_atac.py) \\\n\t\t\t${ta} \\\n\t\t\t${\"--gensz \"+ gensz} \\\n\t\t\t${\"--chrsz \" + chrsz} \\\n\t\t\t${\"--cap-num-peak \" + cap_num_peak} \\\n\t\t\t${\"--pval-thresh \"+ pval_thresh} \\\n\t\t\t${\"--smooth-win \"+ smooth_win} \\\n\t\t\t${if make_signal then \"--make-signal\" else \"\"} \\\n\t\t\t${if keep_irregular_chr_in_bfilt_peak then \"--keep-irregular-chr\" else \"\"} \\\n\t\t\t${\"--blacklist \"+ blacklist}\n\t}\n\toutput {\n\t\tFile npeak = glob(\"*[!.][!b][!f][!i][!l][!t].narrowPeak.gz\")[0]\n\t\tFile bfilt_npeak = glob(\"*.bfilt.narrowPeak.gz\")[0]\n\t\tFile bfilt_npeak_bb = glob(\"*.bfilt.narrowPeak.bb\")[0]\n\t\tArray[File] bfilt_npeak_hammock = glob(\"*.bfilt.narrowPeak.hammock.gz*\")\n\t\tFile sig_pval = if make_signal then glob(\"*.pval.signal.bigwig\")[0] else glob(\"null\")[0]\n\t\tFile sig_fc = if make_signal then glob(\"*.fc.signal.bigwig\")[0] else glob(\"null\")[0]\n\t\tFile frip_qc = glob(\"*.frip.qc\")[0]\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : \"${mem_mb} MB\"\n\t\ttime : time_hr\n\t\tdisks : disks\n\t}\n}\n\ntask idr {\n\tString prefix \t\t# prefix for IDR output file\n\tFile peak1 \t\t\t\n\tFile peak2\n\tFile peak_pooled\n\tFloat idr_thresh\n\tFile blacklist \t# blacklist BED to filter raw peaks\n\tBoolean\tkeep_irregular_chr_in_bfilt_peak\n\t# parameters to compute FRiP\n\tFile? ta\t\t# to calculate FRiP\n\tFile chrsz\t\t\t# 2-col chromosome sizes file\n\tString peak_type\n\tString rank\n\n\tcommand {\n\t\t${if defined(ta) then \"\" else \"touch null.frip.qc\"}\n\t\ttouch null \n\t\tpython $(which encode_idr.py) \\\n\t\t\t${peak1} ${peak2} ${peak_pooled} \\\n\t\t\t${\"--prefix \" + prefix} \\\n\t\t\t${\"--idr-thresh \" + idr_thresh} \\\n\t\t\t${\"--peak-type \" + peak_type} \\\n\t\t\t--idr-rank ${rank} \\\n\t\t\t${\"--chrsz \" + chrsz} \\\n\t\t\t${\"--blacklist \"+ blacklist} \\\n\t\t\t${if keep_irregular_chr_in_bfilt_peak then \"--keep-irregular-chr\" else \"\"} \\\n\t\t\t${\"--ta \" + ta}\n\t}\n\toutput {\n\t\tFile idr_peak = glob(\"*[!.][!b][!f][!i][!l][!t].\"+peak_type+\".gz\")[0]\n\t\tFile bfilt_idr_peak = glob(\"*.bfilt.\"+peak_type+\".gz\")[0]\n\t\tFile bfilt_idr_peak_bb = glob(\"*.bfilt.\"+peak_type+\".bb\")[0]\n\t\tArray[File] bfilt_idr_peak_hammock = glob(\"*.bfilt.\"+peak_type+\".hammock.gz*\")\n\t\tFile idr_plot = glob(\"*.txt.png\")[0]\n\t\tFile idr_unthresholded_peak = glob(\"*.txt.gz\")[0]\n\t\tFile idr_log = glob(\"*.log\")[0]\n\t\tFile frip_qc = if defined(ta) then glob(\"*.frip.qc\")[0] else glob(\"null\")[0]\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : \"8000 MB\"\n\t\ttime : 1\n\t\tdisks : \"local-disk 50 HDD\"\n\t}\t\n}\n\ntask overlap {\n\tString prefix \t\t# prefix for IDR output file\n\tFile peak1\n\tFile peak2\n\tFile peak_pooled\n\tFile blacklist \t# blacklist BED to filter raw peaks\n\tBoolean\tkeep_irregular_chr_in_bfilt_peak\n\tFile? ta\t\t# to calculate FRiP\n\tFile chrsz\t\t\t# 2-col chromosome sizes file\n\tString peak_type\n\n\tcommand {\n\t\t${if defined(ta) then \"\" else \"touch null.frip.qc\"}\n\t\ttouch null \n\t\tpython $(which encode_naive_overlap.py) \\\n\t\t\t${peak1} ${peak2} ${peak_pooled} \\\n\t\t\t${\"--prefix \" + prefix} \\\n\t\t\t${\"--peak-type \" + peak_type} \\\n\t\t\t${\"--chrsz \" + chrsz} \\\n\t\t\t${\"--blacklist \"+ blacklist} \\\n\t\t\t--nonamecheck \\\n\t\t\t${if keep_irregular_chr_in_bfilt_peak then \"--keep-irregular-chr\" else \"\"} \\\n\t\t\t${\"--ta \" + ta}\n\t}\n\toutput {\n\t\tFile overlap_peak = glob(\"*[!.][!b][!f][!i][!l][!t].\"+peak_type+\".gz\")[0]\n\t\tFile bfilt_overlap_peak = glob(\"*.bfilt.\"+peak_type+\".gz\")[0]\n\t\tFile bfilt_overlap_peak_bb = glob(\"*.bfilt.\"+peak_type+\".bb\")[0]\n\t\tArray[File] bfilt_overlap_peak_hammock = glob(\"*.bfilt.\"+peak_type+\".hammock.gz*\")\n\t\tFile frip_qc = if defined(ta) then glob(\"*.frip.qc\")[0] else glob(\"null\")[0]\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : \"4000 MB\"\n\t\ttime : 1\n\t\tdisks : \"local-disk 50 HDD\"\n\t}\n}\n\ntask reproducibility {\n\tString prefix\n\tArray[File]? peaks # peak files from pair of true replicates\n\t\t\t\t\t\t# in a sorted order. for example of 4 replicates,\n\t\t\t\t\t\t# 1,2 1,3 1,4 2,3 2,4 3,4.\n                        # x,y means peak file from rep-x vs rep-y\n\tArray[File]? peaks_pr\t# peak files from pseudo replicates\n\tFile? peak_ppr\t\t\t# Peak file from pooled pseudo replicate.\n\tString peak_type\n\tFile chrsz\t\t\t# 2-col chromosome sizes file\n\tBoolean\tkeep_irregular_chr_in_bfilt_peak\n\n\tcommand {\n\t\tpython $(which encode_reproducibility_qc.py) \\\n\t\t\t${sep=' ' peaks} \\\n\t\t\t--peaks-pr ${sep=' ' peaks_pr} \\\n\t\t\t${\"--peak-ppr \"+ peak_ppr} \\\n\t\t\t--prefix ${prefix} \\\n\t\t\t${\"--peak-type \" + peak_type} \\\n\t\t\t${if keep_irregular_chr_in_bfilt_peak then \"--keep-irregular-chr\" else \"\"} \\\n\t\t\t${\"--chrsz \" + chrsz}\n\t}\n\toutput {\n\t\tFile optimal_peak = glob(\"optimal_peak.*.gz\")[0]\n\t\tFile conservative_peak = glob(\"conservative_peak.*.gz\")[0]\n\t\tFile optimal_peak_bb = glob(\"optimal_peak.*.bb\")[0]\n\t\tFile conservative_peak_bb = glob(\"conservative_peak.*.bb\")[0]\n\t\tArray[File] optimal_peak_hammock = glob(\"optimal_peak.*.hammock.gz*\")\n\t\tArray[File] conservative_peak_hammock = glob(\"conservative_peak.*.hammock.gz*\")\n\t\tFile reproducibility_qc = glob(\"*reproducibility.qc\")[0]\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : \"4000 MB\"\n\t\ttime : 1\n\t\tdisks : \"local-disk 50 HDD\"\n\t}\n}\n\ntask ataqc { # generate ATAQC report\n\tBoolean paired_end\n\tFile? read_len_log\n\tFile? flagstat_log\n\tFile? bowtie2_log\n\tFile? bam\n\tFile? nodup_flagstat_log\n\tFile? mito_dup_log\n\tFile? dup_log\n\tFile? pbc_log\n\tFile? nodup_bam\n\tFile? ta\n\tFile? peak\n\tFile? idr_peak \n\tFile? overlap_peak\n\tFile? bigwig\n\t# from genome database\n\tFile? ref_fa\n\tFile? chrsz\n\tFile? tss_enrich\n\tFile? blacklist\n\tFile? dnase\n\tFile? prom\n\tFile? enh\n\tFile? reg2map_bed\n\tFile? reg2map\n\tFile? roadmap_meta\n\tString mito_chr_name\n\n\tInt mem_mb\n\tInt mem_java_mb\n\tInt time_hr\n\tString disks\n\n\tcommand {\n\t\texport _JAVA_OPTIONS=\"-Xms256M -Xmx${mem_java_mb}M -XX:ParallelGCThreads=1 $_JAVA_OPTIONS\"\n\n\t\tpython $(which encode_ataqc.py) \\\n\t\t\t${if paired_end then \"--paired-end\" else \"\"} \\\n\t\t\t${\"--read-len-log \" + read_len_log} \\\n\t\t\t${\"--flagstat-log \" + flagstat_log} \\\n\t\t\t${\"--bowtie2-log \" + bowtie2_log} \\\n\t\t\t${\"--bam \" + bam} \\\n\t\t\t${\"--nodup-flagstat-log \" + nodup_flagstat_log} \\\n\t\t\t${\"--mito-dup-log \" + mito_dup_log} \\\n\t\t\t${\"--dup-log \" + dup_log} \\\n\t\t\t${\"--pbc-log \" + pbc_log} \\\n\t\t\t${\"--nodup-bam \" + nodup_bam} \\\n\t\t\t${\"--ta \" + ta} \\\n\t\t\t${\"--bigwig \" + bigwig} \\\n\t\t\t${\"--peak \" + peak} \\\n\t\t\t${\"--idr-peak \" + idr_peak} \\\n\t\t\t${\"--overlap-peak \" + overlap_peak} \\\n\t\t\t${\"--ref-fa \" + ref_fa} \\\n\t\t\t${\"--blacklist \" + blacklist} \\\n\t\t\t${\"--chrsz \" + chrsz} \\\n\t\t\t${\"--dnase \" + dnase} \\\n\t\t\t${\"--tss-enrich \" + tss_enrich} \\\n\t\t\t${\"--prom \" + prom} \\\n\t\t\t${\"--enh \" + enh} \\\n\t\t\t${\"--reg2map-bed \" + reg2map_bed} \\\n\t\t\t${\"--reg2map \" + reg2map} \\\n\t\t\t${\"--roadmap-meta \" + roadmap_meta} \\\n\t\t\t${\"--mito-chr-name \" + mito_chr_name}\n\n\t}\n\toutput {\n\t\tFile html = glob(\"*_qc.html\")[0]\n\t\tFile txt = glob(\"*_qc.txt\")[0]\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : \"${mem_mb} MB\"\n\t\ttime : time_hr\n\t\tdisks : disks\n\t}\n}\n\n# gather all outputs and generate \n# - qc.html\t\t: organized final HTML report\n# - qc.json\t\t: all QCs\ntask qc_report {\n\t# optional metadata\n\tString pipeline_ver\n \tString title # name of sample\n\tString description # description for sample\n\tString? genome\n\t#String? encode_accession_id\t# ENCODE accession ID of sample\n\t# workflow params\n\tInt multimapping\n\tBoolean paired_end\n\tString pipeline_type\n\tString peak_caller\n\tInt? macs2_cap_num_peak\n\tInt? spp_cap_num_peak\n\tFloat idr_thresh\n\t# QCs\n\tArray[File]? flagstat_qcs\n\tArray[File]? nodup_flagstat_qcs\n\tArray[File]? dup_qcs\n\tArray[File]? pbc_qcs\n\tArray[File]? xcor_plots\n\tArray[File]? xcor_scores\n\tArray[File]? idr_plots\n\tArray[File]? idr_plots_pr\n\tFile? idr_plot_ppr\n\tArray[File]? frip_macs2_qcs\n\tArray[File]? frip_macs2_qcs_pr1\n\tArray[File]? frip_macs2_qcs_pr2\n\tFile? frip_macs2_qc_pooled\n\tFile? frip_macs2_qc_ppr1 \n\tFile? frip_macs2_qc_ppr2 \n\tArray[File]? frip_idr_qcs\n\tArray[File]? frip_idr_qcs_pr\n\tFile? frip_idr_qc_ppr \n\tArray[File]? frip_overlap_qcs\n\tArray[File]? frip_overlap_qcs_pr\n\tFile? frip_overlap_qc_ppr\n\tFile? idr_reproducibility_qc\n\tFile? overlap_reproducibility_qc\n\tArray[File]? ataqc_txts\n\tArray[File]? ataqc_htmls\n\n\tFile? qc_json_ref\n\n\tcommand {\n\t\tpython $(which encode_qc_report.py) \\\n\t\t\t${\"--pipeline-ver \" + pipeline_ver} \\\n\t\t\t${\"--title '\" + sub(title,\"'\",\"_\") + \"'\"} \\\n\t\t\t${\"--desc '\" + sub(description,\"'\",\"_\") + \"'\"} \\\n\t\t\t${\"--genome \" + genome} \\\n\t\t\t${\"--multimapping \" + multimapping} \\\n\t\t\t${if paired_end then \"--paired-end\" else \"\"} \\\n\t\t\t--pipeline-type ${pipeline_type} \\\n\t\t\t--peak-caller ${peak_caller} \\\n\t\t\t${\"--macs2-cap-num-peak \" + macs2_cap_num_peak} \\\n\t\t\t${\"--spp-cap-num-peak \" + spp_cap_num_peak} \\\n\t\t\t--idr-thresh ${idr_thresh} \\\n\t\t\t--flagstat-qcs ${sep=' ' flagstat_qcs} \\\n\t\t\t--nodup-flagstat-qcs ${sep=' ' nodup_flagstat_qcs} \\\n\t\t\t--dup-qcs ${sep=' ' dup_qcs} \\\n\t\t\t--pbc-qcs ${sep=' ' pbc_qcs} \\\n\t\t\t--xcor-plots ${sep=' ' xcor_plots} \\\n\t\t\t--xcor-scores ${sep=' ' xcor_scores} \\\n\t\t\t--idr-plots ${sep=' ' idr_plots} \\\n\t\t\t--idr-plots-pr ${sep=' ' idr_plots_pr} \\\n\t\t\t${\"--idr-plot-ppr \" + idr_plot_ppr} \\\n\t\t\t--frip-macs2-qcs ${sep=' ' frip_macs2_qcs} \\\n\t\t\t--frip-macs2-qcs-pr1 ${sep=' ' frip_macs2_qcs_pr1} \\\n\t\t\t--frip-macs2-qcs-pr2 ${sep=' ' frip_macs2_qcs_pr2} \\\n\t\t\t${\"--frip-macs2-qc-pooled \" + frip_macs2_qc_pooled} \\\n\t\t\t${\"--frip-macs2-qc-ppr1 \" + frip_macs2_qc_ppr1} \\\n\t\t\t${\"--frip-macs2-qc-ppr2 \" + frip_macs2_qc_ppr2} \\\n\t\t\t--frip-idr-qcs ${sep=' ' frip_idr_qcs} \\\n\t\t\t--frip-idr-qcs-pr ${sep=' ' frip_idr_qcs_pr} \\\n\t\t\t${\"--frip-idr-qc-ppr \" + frip_idr_qc_ppr} \\\n\t\t\t--frip-overlap-qcs ${sep=' ' frip_overlap_qcs} \\\n\t\t\t--frip-overlap-qcs-pr ${sep=' ' frip_overlap_qcs_pr} \\\n\t\t\t${\"--frip-overlap-qc-ppr \" + frip_overlap_qc_ppr} \\\n\t\t\t${\"--idr-reproducibility-qc \" + idr_reproducibility_qc} \\\n\t\t\t${\"--overlap-reproducibility-qc \" + overlap_reproducibility_qc} \\\n\t\t\t--ataqc-txts ${sep=' ' ataqc_txts} \\\n\t\t\t--ataqc-htmls ${sep=' ' ataqc_htmls} \\\n\t\t\t--out-qc-html qc.html \\\n\t\t\t--out-qc-json qc.json \\\n\t\t\t${\"--qc-json-ref \" + qc_json_ref}\t\t\n\t}\n\toutput {\n\t\tFile report = glob('*qc.html')[0]\n\t\tFile qc_json = glob('*qc.json')[0]\n\t\tBoolean qc_json_ref_match = read_string(\"qc_json_ref_match.txt\")==\"True\"\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : \"4000 MB\"\n\t\ttime : 1\n\t\tdisks : \"local-disk 50 HDD\"\t\t\n\t}\n}\n\ntask read_genome_tsv {\n\tFile genome_tsv\n\tcommand {\n\t\tcat ${genome_tsv} > 'tmp.tsv'\n\t}\n\toutput {\n\t\tMap[String,String] genome = read_map('tmp.tsv')\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : \"4000 MB\"\n\t\ttime : 1\n\t\tdisks : \"local-disk 50 HDD\"\t\t\n\t}\n}\n\ntask compare_md5sum {\n\tArray[String] labels\n\tArray[File] files\n\tArray[File] ref_files\n\n\tcommand <<<\n\t\tpython <<CODE\t\n\t\tfrom collections import OrderedDict\n\t\timport os\n\t\timport json\n\t\timport hashlib\n\n\t\tdef md5sum(filename, blocksize=65536):\n\t\t    hash = hashlib.md5()\n\t\t    with open(filename, 'rb') as f:\n\t\t        for block in iter(lambda: f.read(blocksize), b\"\"):\n\t\t            hash.update(block)\n\t\t    return hash.hexdigest()\n\n\t\twith open('${write_lines(labels)}','r') as fp:\n\t\t\tlabels = fp.read().splitlines()\n\t\twith open('${write_lines(files)}','r') as fp:\n\t\t\tfiles = fp.read().splitlines()\n\t\twith open('${write_lines(ref_files)}','r') as fp:\n\t\t\tref_files = fp.read().splitlines()\n\n\t\tresult = OrderedDict()\n\t\tmatch = OrderedDict()\n\t\tmatch_overall = True\n\n\t\tresult['tasks'] = []\n\t\tresult['failed_task_labels'] = []\n\t\tresult['succeeded_task_labels'] = []\n\t\tfor i, label in enumerate(labels):\n\t\t\tf = files[i]\n\t\t\tref_f = ref_files[i]\n\t\t\tmd5 = md5sum(f)\n\t\t\tref_md5 = md5sum(ref_f)\n\t\t\t# if text file, read in contents\n\t\t\tif f.endswith('.qc') or f.endswith('.txt') or \\\n\t\t\t\tf.endswith('.log') or f.endswith('.out'):\n\t\t\t\twith open(f,'r') as fp:\n\t\t\t\t\tcontents = fp.read()\n\t\t\t\twith open(ref_f,'r') as fp:\n\t\t\t\t\tref_contents = fp.read()\n\t\t\telse:\n\t\t\t\tcontents = ''\n\t\t\t\tref_contents = ''\n\t\t\tmatched = md5==ref_md5\n\t\t\tresult['tasks'].append(OrderedDict([\n\t\t\t\t('label', label),\n\t\t\t\t('match', matched),\n\t\t\t\t('md5sum', md5),\n\t\t\t\t('ref_md5sum', ref_md5),\n\t\t\t\t('basename', os.path.basename(f)),\n\t\t\t\t('ref_basename', os.path.basename(ref_f)),\n\t\t\t\t('contents', contents),\n\t\t\t\t('ref_contents', ref_contents),\n\t\t\t\t]))\n\t\t\tmatch[label] = matched\n\t\t\tmatch_overall &= matched\n\t\t\tif matched:\n\t\t\t\tresult['succeeded_task_labels'].append(label)\n\t\t\telse:\n\t\t\t\tresult['failed_task_labels'].append(label)\t\t\n\t\tresult['match_overall'] = match_overall\n\n\t\twith open('result.json','w') as fp:\n\t\t\tfp.write(json.dumps(result, indent=4))\n\t\tmatch_tmp = []\n\t\tfor key in match:\n\t\t\tval = match[key]\n\t\t\tmatch_tmp.append('{}\\t{}'.format(key, val))\n\t\twith open('match.tsv','w') as fp:\n\t\t\tfp.writelines('\\n'.join(match_tmp))\n\t\twith open('match_overall.txt','w') as fp:\n\t\t\tfp.write(str(match_overall))\n\t\tCODE\n\t>>>\n\toutput {\n\t\tMap[String,String] match = read_map('match.tsv') # key:label, val:match\n\t\tBoolean match_overall = read_boolean('match_overall.txt')\n\t\tFile json = glob('result.json')[0] # details (json file)\n\t\tString json_str = read_string('result.json') # details (string)\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : \"4000 MB\"\n\t\ttime : 1\n\t\tdisks : \"local-disk 50 HDD\"\t\t\n\t}\n}\n",
    "root": "None",
    "options": "{\n\n}",
    "inputs": "{\n    \"atac.pipeline_type\" : \"atac\",\n    \"atac.genome_tsv\" : \"test_genome_database/hg38_local.tsv\",\n    \"atac.fastqs\" : [\n        [\n            [\"test_sample/ENCSR356KRQ/fastq_subsampled/rep1/pair1/ENCFF341MYG.subsampled.400.fastq.gz\",\n             \"test_sample/ENCSR356KRQ/fastq_subsampled/rep1/pair2/ENCFF248EJF.subsampled.400.fastq.gz\"],\n            [\"test_sample/ENCSR356KRQ/fastq_subsampled/rep1/pair1/ENCFF106QGY.subsampled.400.fastq.gz\",\n             \"test_sample/ENCSR356KRQ/fastq_subsampled/rep1/pair2/ENCFF368TYI.subsampled.400.fastq.gz\"]\n        ],\n        [\n            [\"test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF641SFZ.subsampled.400.fastq.gz\",\n             \"test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF031ARQ.subsampled.400.fastq.gz\"],\n            [\"test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF751XTV.subsampled.400.fastq.gz\",\n             \"test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF590SYZ.subsampled.400.fastq.gz\"],\n            [\"test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF927LSG.subsampled.400.fastq.gz\",\n             \"test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF734PEQ.subsampled.400.fastq.gz\"],\n            [\"test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF859BDM.subsampled.400.fastq.gz\",\n             \"test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF007USV.subsampled.400.fastq.gz\"],\n            [\"test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF193RRC.subsampled.400.fastq.gz\",\n             \"test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF886FSC.subsampled.400.fastq.gz\"],\n            [\"test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF366DFI.subsampled.400.fastq.gz\",\n             \"test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF573UXK.subsampled.400.fastq.gz\"]\n        ]\n    ],\n\n    \"atac.paired_end\" : true,\n    \"atac.multimapping\" : 4,\n\n    \"atac.auto_detect_adapter\" : true,\n\n    \"atac.smooth_win\" : 73,\n    \"atac.enable_idr\" : true,\n    \"atac.idr_thresh\" : 0.05,\n\n    \"atac.enable_xcor\" : true,\n\n    \"atac.title\" : \"ENCSR356KRQ (subsampled 1/400 reads)\",\n    \"atac.description\" : \"ATAC-seq on primary keratinocytes in day 0.0 of differentiation\",\n\n    \"atac.trim_adapter.cpu\" : 1,\n    \"atac.trim_adapter.mem_mb\" : 4000,\n    \"atac.trim_adapter.time_hr\" : 1,\n    \"atac.bowtie2_cpu\" : 1,\n    \"atac.bowtie2_mem_mb\" : 4000,\n    \"atac.bowtie2_time_hr\" : 1,\n    \"atac.filter_cpu\" : 1,\n    \"atac.filter_mem_mb\" : 4000,\n    \"atac.filter_time_hr\" : 1,\n    \"atac.macs2_mem_mb\" : 4000,\n    \"atac.macs2_time_hr\" : 1,\n    \"atac.ataqc.mem_mb\" : 5000,\n    \"atac.ataqc.mem_java_mb\" : 4000,\n    \"atac.ataqc.time_hr\" : 1\n}\n",
    "labels": "{}"
  },
  "calls": {
    "atac.trim_adapter": [{
      "retryableFailure": false,
      "executionStatus": "Failed",
      "stdout": "/sulb1/mmalfait/atac-seq-pipeline/cromwell-executions/atac/99f85091-2946-4f78-9f38-934655c5911a/call-trim_adapter/shard-0/execution/stdout",
      "backendStatus": "Done",
      "shardIndex": 0,
      "runtimeAttributes": {
        "failOnStderr": "false",
        "continueOnReturnCode": "0",
        "maxRetries": "0"
      },
      "callCaching": {
        "effectiveCallCachingMode": "CallCachingOff",
        "allowResultReuse": false
      },
      "inputs": {
        "auto_detect_adapter": true,
        "fastqs": [["test_sample/ENCSR356KRQ/fastq_subsampled/rep1/pair1/ENCFF341MYG.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep1/pair2/ENCFF248EJF.subsampled.400.fastq.gz"], ["test_sample/ENCSR356KRQ/fastq_subsampled/rep1/pair1/ENCFF106QGY.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep1/pair2/ENCFF368TYI.subsampled.400.fastq.gz"]],
        "mem_mb": 12000,
        "time_hr": 24,
        "disks": "local-disk 100 HDD",
        "cpu": 2,
        "paired_end": true,
        "adapters": [],
        "err_rate": 0.1,
        "min_trim_len": 5
      },
      "returnCode": 1,
      "failures": [{
        "causedBy": [],
        "message": "Job atac.trim_adapter:0:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."
      }],
      "jobId": "9767",
      "backend": "Local",
      "end": "2019-03-11T18:21:06.248+01:00",
      "stderr": "/sulb1/mmalfait/atac-seq-pipeline/cromwell-executions/atac/99f85091-2946-4f78-9f38-934655c5911a/call-trim_adapter/shard-0/execution/stderr",
      "callRoot": "/sulb1/mmalfait/atac-seq-pipeline/cromwell-executions/atac/99f85091-2946-4f78-9f38-934655c5911a/call-trim_adapter/shard-0",
      "attempt": 1,
      "executionEvents": [{
        "startTime": "2019-03-11T18:21:04.050+01:00",
        "endTime": "2019-03-11T18:21:04.050+01:00",
        "description": "Pending"
      }, {
        "endTime": "2019-03-11T18:21:06.247+01:00",
        "description": "RunningJob",
        "startTime": "2019-03-11T18:21:04.074+01:00"
      }, {
        "description": "PreparingJob",
        "startTime": "2019-03-11T18:21:04.068+01:00",
        "endTime": "2019-03-11T18:21:04.074+01:00"
      }, {
        "endTime": "2019-03-11T18:21:06.247+01:00",
        "description": "UpdatingJobStore",
        "startTime": "2019-03-11T18:21:06.247+01:00"
      }, {
        "endTime": "2019-03-11T18:21:04.067+01:00",
        "description": "RequestingExecutionToken",
        "startTime": "2019-03-11T18:21:04.050+01:00"
      }, {
        "description": "WaitingForValueStore",
        "startTime": "2019-03-11T18:21:04.067+01:00",
        "endTime": "2019-03-11T18:21:04.068+01:00"
      }],
      "start": "2019-03-11T18:21:04.050+01:00"
    }, {
      "retryableFailure": false,
      "executionStatus": "Failed",
      "stdout": "/sulb1/mmalfait/atac-seq-pipeline/cromwell-executions/atac/99f85091-2946-4f78-9f38-934655c5911a/call-trim_adapter/shard-1/execution/stdout",
      "backendStatus": "Done",
      "shardIndex": 1,
      "runtimeAttributes": {
        "failOnStderr": "false",
        "continueOnReturnCode": "0",
        "maxRetries": "0"
      },
      "callCaching": {
        "effectiveCallCachingMode": "CallCachingOff",
        "allowResultReuse": false
      },
      "inputs": {
        "auto_detect_adapter": true,
        "fastqs": [["test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF641SFZ.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF031ARQ.subsampled.400.fastq.gz"], ["test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF751XTV.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF590SYZ.subsampled.400.fastq.gz"], ["test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF927LSG.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF734PEQ.subsampled.400.fastq.gz"], ["test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF859BDM.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF007USV.subsampled.400.fastq.gz"], ["test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF193RRC.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF886FSC.subsampled.400.fastq.gz"], ["test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF366DFI.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF573UXK.subsampled.400.fastq.gz"]],
        "mem_mb": 12000,
        "time_hr": 24,
        "disks": "local-disk 100 HDD",
        "cpu": 2,
        "paired_end": true,
        "adapters": [],
        "err_rate": 0.1,
        "min_trim_len": 5
      },
      "returnCode": 1,
      "failures": [{
        "message": "Job atac.trim_adapter:1:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.",
        "causedBy": []
      }],
      "jobId": "9775",
      "backend": "Local",
      "end": "2019-03-11T18:21:06.251+01:00",
      "stderr": "/sulb1/mmalfait/atac-seq-pipeline/cromwell-executions/atac/99f85091-2946-4f78-9f38-934655c5911a/call-trim_adapter/shard-1/execution/stderr",
      "callRoot": "/sulb1/mmalfait/atac-seq-pipeline/cromwell-executions/atac/99f85091-2946-4f78-9f38-934655c5911a/call-trim_adapter/shard-1",
      "attempt": 1,
      "executionEvents": [{
        "endTime": "2019-03-11T18:21:04.050+01:00",
        "description": "Pending",
        "startTime": "2019-03-11T18:21:04.050+01:00"
      }, {
        "startTime": "2019-03-11T18:21:06.247+01:00",
        "endTime": "2019-03-11T18:21:06.247+01:00",
        "description": "UpdatingJobStore"
      }, {
        "startTime": "2019-03-11T18:21:04.050+01:00",
        "endTime": "2019-03-11T18:21:04.067+01:00",
        "description": "RequestingExecutionToken"
      }, {
        "endTime": "2019-03-11T18:21:04.072+01:00",
        "description": "PreparingJob",
        "startTime": "2019-03-11T18:21:04.068+01:00"
      }, {
        "startTime": "2019-03-11T18:21:04.072+01:00",
        "endTime": "2019-03-11T18:21:06.247+01:00",
        "description": "RunningJob"
      }, {
        "description": "WaitingForValueStore",
        "endTime": "2019-03-11T18:21:04.068+01:00",
        "startTime": "2019-03-11T18:21:04.067+01:00"
      }],
      "start": "2019-03-11T18:21:04.050+01:00"
    }],
    "atac.read_genome_tsv": [{
      "executionStatus": "Done",
      "stdout": "/sulb1/mmalfait/atac-seq-pipeline/cromwell-executions/atac/99f85091-2946-4f78-9f38-934655c5911a/call-read_genome_tsv/execution/stdout",
      "backendStatus": "Done",
      "shardIndex": -1,
      "outputs": {
        "genome": {
          "blacklist": "test_genome_database/hg38/hg38.blacklist.bed.gz",
          "enh": "test_genome_database/hg38/ataqc/reg2map_honeybadger2_dnase_enh_p2.hg19_to_hg38.bed.gz",
          "ref_fa": "test_genome_database/hg38/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta.gz",
          "reg2map": "test_genome_database/hg38/ataqc/hg38_dnase_avg_fseq_signal_formatted.txt.gz",
          "bwa_idx_tar": "test_genome_database/hg38/bwa_index/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta.tar",
          "roadmap_meta": "test_genome_database/hg38/ataqc/hg38_dnase_avg_fseq_signal_metadata.txt",
          "chrsz": "test_genome_database/hg38/hg38.chrom.sizes",
          "bowtie2_idx_tar": "test_genome_database/hg38/bowtie2_index/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta.tar",
          "reg2map_bed": "test_genome_database/hg38/ataqc/hg38_celltype_compare_subsample.bed.gz",
          "gensz": "hs",
          "tss_enrich": "test_genome_database/hg38/ataqc/hg38_gencode_tss_unique.bed.gz",
          "prom": "test_genome_database/hg38/ataqc/reg2map_honeybadger2_dnase_prom_p2.hg19_to_hg38.bed.gz",
          "dnase": "test_genome_database/hg38/ataqc/reg2map_honeybadger2_dnase_all_p10_ucsc.hg19_to_hg38.bed.gz"
        }
      },
      "runtimeAttributes": {
        "failOnStderr": "false",
        "maxRetries": "0",
        "continueOnReturnCode": "0"
      },
      "callCaching": {
        "effectiveCallCachingMode": "CallCachingOff",
        "allowResultReuse": false
      },
      "inputs": {
        "genome_tsv": "test_genome_database/hg38_local.tsv"
      },
      "returnCode": 0,
      "jobId": "9734",
      "backend": "Local",
      "end": "2019-03-11T18:21:01.294+01:00",
      "stderr": "/sulb1/mmalfait/atac-seq-pipeline/cromwell-executions/atac/99f85091-2946-4f78-9f38-934655c5911a/call-read_genome_tsv/execution/stderr",
      "callRoot": "/sulb1/mmalfait/atac-seq-pipeline/cromwell-executions/atac/99f85091-2946-4f78-9f38-934655c5911a/call-read_genome_tsv",
      "attempt": 1,
      "executionEvents": [{
        "description": "RequestingExecutionToken",
        "startTime": "2019-03-11T18:20:57.928+01:00",
        "endTime": "2019-03-11T18:20:58.076+01:00"
      }, {
        "endTime": "2019-03-11T18:20:58.129+01:00",
        "startTime": "2019-03-11T18:20:58.082+01:00",
        "description": "PreparingJob"
      }, {
        "description": "RunningJob",
        "endTime": "2019-03-11T18:21:01.293+01:00",
        "startTime": "2019-03-11T18:20:58.129+01:00"
      }, {
        "startTime": "2019-03-11T18:21:01.293+01:00",
        "endTime": "2019-03-11T18:21:01.295+01:00",
        "description": "UpdatingJobStore"
      }, {
        "endTime": "2019-03-11T18:20:58.082+01:00",
        "description": "WaitingForValueStore",
        "startTime": "2019-03-11T18:20:58.076+01:00"
      }, {
        "description": "Pending",
        "startTime": "2019-03-11T18:20:57.917+01:00",
        "endTime": "2019-03-11T18:20:57.928+01:00"
      }],
      "start": "2019-03-11T18:20:57.907+01:00"
    }]
  },
  "outputs": {

  },
  "workflowRoot": "/sulb1/mmalfait/atac-seq-pipeline/cromwell-executions/atac/99f85091-2946-4f78-9f38-934655c5911a",
  "actualWorkflowLanguage": "WDL",
  "id": "99f85091-2946-4f78-9f38-934655c5911a",
  "inputs": {
    "atac.adapters_rep6_R2": [],
    "atac.macs2_time_hr": 1,
    "atac.nodup_flagstat_qcs": [],
    "atac.peak_pooled": null,
    "atac.peaks_pr2": [],
    "atac.fastqs_rep2_R2": [],
    "atac.keep_irregular_chr_in_bfilt_peak": false,
    "atac.qc_report.spp_cap_num_peak": null,
    "atac.adapters_rep2_R2": [],
    "atac.bam2ta_time_hr": 6,
    "atac.pipeline_type": "atac",
    "atac.align_only": false,
    "atac.fastqs_rep1_R1": [],
    "atac.trim_adapter_cpu": 2,
    "atac.mito_chr_name": "chrM",
    "atac.filter_mem_mb": 4000,
    "atac.dup_marker": "picard",
    "atac.read_len_logs": [],
    "atac.bam2ta_mem_mb": 10000,
    "atac.ataqc_mem_mb": 16000,
    "atac.trim_adapter_time_hr": 24,
    "atac.macs2_frip_qcs": [],
    "atac.pipeline_ver": "v1.1.6",
    "atac.macs2_mem_mb": 4000,
    "atac.adapters": [],
    "atac.bowtie2_score_min": "",
    "atac.macs2_pr2_frip_qcs": [],
    "atac.auto_detect_adapter": true,
    "atac.trim_adapter_disks": "local-disk 100 HDD",
    "atac.xcor_time_hr": 6,
    "atac.fastqs_rep6_R1": [],
    "atac.adapters_rep5_R2": [],
    "atac.adapters_rep1_R1": [],
    "atac.adapters_rep5_R1": [],
    "atac.no_dup_removal": false,
    "atac.adapters_rep3_R1": [],
    "atac.qc_report.qc_json_ref": null,
    "atac.idr_thresh": 0.05,
    "atac.adapters_rep1_R2": [],
    "atac.cutadapt_min_trim_len": 5,
    "atac.subsample_reads": 0,
    "atac.xcor_subsample_reads": 25000000,
    "atac.peak_ppr2": null,
    "atac.dup_qcs": [],
    "atac.ataqc_htmls": [],
    "atac.true_rep_only": false,
    "atac.bowtie2_disks": "local-disk 100 HDD",
    "atac.bams": [],
    "atac.peak_type": "narrowPeak",
    "atac.fastqs_rep2_R1": [],
    "atac.fastqs_rep3_R1": [],
    "atac.align_logs": [],
    "atac.bowtie2_cpu": 1,
    "atac.spr_mem_mb": 16000,
    "atac.fastqs_rep6_R2": [],
    "atac.ataqc_disks": "local-disk 400 HDD",
    "atac.ta_pooled": null,
    "atac.filter_cpu": 1,
    "atac.adapters_rep3_R2": [],
    "atac.fastqs_rep5_R2": [],
    "atac.adapters_rep4_R1": [],
    "atac.macs2_disks": "local-disk 100 HDD",
    "atac.regex_filter_reads": "chrM",
    "atac.adapters_rep2_R1": [],
    "atac.xcor_plots": [],
    "atac.fastqs_rep4_R2": [],
    "atac.filter_time_hr": 1,
    "atac.peaks": [],
    "atac.description": "ATAC-seq on primary keratinocytes in day 0.0 of differentiation",
    "atac.fastqs_rep4_R1": [],
    "atac.filter_disks": "local-disk 100 HDD",
    "atac.ataqc_mem_java_mb": 15000,
    "atac.tas": [],
    "atac.enable_xcor": true,
    "atac.title": "ENCSR356KRQ (subsampled 1/400 reads)",
    "atac.flagstat_qcs": [],
    "atac.bam2ta_cpu": 2,
    "atac.bowtie2_time_hr": 1,
    "atac.pval_thresh": 0.01,
    "atac.macs2_pr1_frip_qcs": [],
    "atac.bam2ta_disks": "local-disk 100 HDD",
    "atac.cutadapt_err_rate": 0.1,
    "atac.pbc_qcs": [],
    "atac.peaks_pr1": [],
    "atac.fastqs_rep1_R2": [],
    "atac.adapters_rep6_R1": [],
    "atac.nodup_bams": [],
    "atac.cap_num_peak": 300000,
    "atac.xcor_cpu": 2,
    "atac.trim_adapter_mem_mb": 12000,
    "atac.disable_ataqc": false,
    "atac.adapters_rep4_R2": [],
    "atac.sig_pvals": [],
    "atac.idr_rank": "p.value",
    "atac.macs2_ppr2_frip_qc_": null,
    "atac.multimapping": 4,
    "atac.fastqs_rep5_R1": [],
    "atac.xcor_mem_mb": 16000,
    "atac.macs2_pooled_frip_qc_": null,
    "atac.fastqs": [[["test_sample/ENCSR356KRQ/fastq_subsampled/rep1/pair1/ENCFF341MYG.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep1/pair2/ENCFF248EJF.subsampled.400.fastq.gz"], ["test_sample/ENCSR356KRQ/fastq_subsampled/rep1/pair1/ENCFF106QGY.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep1/pair2/ENCFF368TYI.subsampled.400.fastq.gz"]], [["test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF641SFZ.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF031ARQ.subsampled.400.fastq.gz"], ["test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF751XTV.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF590SYZ.subsampled.400.fastq.gz"], ["test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF927LSG.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF734PEQ.subsampled.400.fastq.gz"], ["test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF859BDM.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF007USV.subsampled.400.fastq.gz"], ["test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF193RRC.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF886FSC.subsampled.400.fastq.gz"], ["test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair1/ENCFF366DFI.subsampled.400.fastq.gz", "test_sample/ENCSR356KRQ/fastq_subsampled/rep2/pair2/ENCFF573UXK.subsampled.400.fastq.gz"]]],
    "atac.mapq_thresh": 30,
    "atac.fastqs_rep3_R2": [],
    "atac.bowtie2_mem_mb": 4000,
    "atac.macs2_ppr1_frip_qc_": null,
    "atac.genome_tsv": "test_genome_database/hg38_local.tsv",
    "atac.xcor_scores": [],
    "atac.xcor_disks": "local-disk 100 HDD",
    "atac.ataqc_txts": [],
    "atac.null": null,
    "atac.paired_end": true,
    "atac.ataqc_time_hr": 24,
    "atac.peak_ppr1": null,
    "atac.mito_dup_logs": [],
    "atac.enable_idr": true,
    "atac.smooth_win": 73
  },
  "labels": {
    "cromwell-workflow-id": "cromwell-99f85091-2946-4f78-9f38-934655c5911a"
  },
  "submission": "2019-03-11T18:20:27.138+01:00",
  "status": "Failed",
  "failures": [{
    "message": "Workflow failed",
    "causedBy": [{
      "message": "Job atac.trim_adapter:0:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.",
      "causedBy": []
    }, {
      "message": "Job atac.trim_adapter:1:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.",
      "causedBy": []
    }]
  }],
  "end": "2019-03-11T18:21:07.129+01:00",
  "start": "2019-03-11T18:20:27.240+01:00"
}